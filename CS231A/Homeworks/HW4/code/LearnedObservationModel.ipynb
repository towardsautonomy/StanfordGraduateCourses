{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LearnedObservationModel",
      "provenance": [],
      "collapsed_sections": [
        "3b2iaKy1OJLu"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBciS_TD3JVl"
      },
      "source": [
        "# CS231a PSET 4 Problem 3: Linear Kalman Filter with a Learned Inverse Observation Model\n",
        "\n",
        "Building on the idea of learning useful representations for downstream tasks we saw in the last problem, in this problem you will see how this can be done for the task of monocular depth estimation.\n",
        "\n",
        "**Using a GPU**. Make sure to first change your runtime to use a GPU: click Runtime -> Change runtime type -> Hardware Accelerator -> GPU and your Colab instance will automatically be backed by GPU compute.\n",
        "\n",
        "Note: there is a known issue of the RAM running out while loading the second set of data after training. To get around this, after training please just restart the runtime and rerun the first 3 cells (prior to loading the training data) followed by the cells under 'Using the model'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOicjBkxBg6Q"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwQRvE4C3gf5"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# enter the foldername in your Drive where you have saved the data\n",
        "# folder from the pset folder\n",
        "# e.g. '/content/drive/MyDrive/cs231a/learned_observation_model'\n",
        "FOLDERNAME = None\n",
        "\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "%cd drive/My\\ Drive\n",
        "%cd $FOLDERNAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM_rDf34_xC5"
      },
      "source": [
        "# Loading the data for part A\n",
        "\n",
        "Let's start by loading our datasets into memory:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJqDYf2__-HF"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "import gc\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZS7hG29LQUR"
      },
      "source": [
        "def load_dataset(root, split=\"train\"):\n",
        "    labels = np.load(root + 'Q3A_positions_'+split+'.npy')\n",
        "    num_images = labels.shape[0]\n",
        "    images = np.empty(shape=(num_images, 480, 640,3))\n",
        "    for i in tqdm(range(num_images), desc='Loading data'):\n",
        "        im = Image.open(root + 'img_%03d_%s.png'%(i,split))\n",
        "        images[i] = np.array(im)/255.0\n",
        "    return images, labels\n",
        "\n",
        "image_train, label_train = load_dataset('./data/Q3A_data/training_set/', 'train')\n",
        "image_test, label_test = load_dataset('./data/Q3A_data/testing_set/', 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5YXdgoFHIiI"
      },
      "source": [
        "n = 3\n",
        "fig, axs = plt.subplots(n)\n",
        "for i in range(n):\n",
        "    idx = i\n",
        "    img = image_train[idx]\n",
        "    axs[i].imshow(img)\n",
        "    axs[i].set_title('Train image %d, label %s'%(idx,str(label_train[idx])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTffBCOz7qwz"
      },
      "source": [
        "# Training the Model\n",
        "\n",
        "Next, we can go ahead and train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZqgjjPU9HvL"
      },
      "source": [
        "def make_model(input):\n",
        "    conv1_1 = tf.keras.layers.Conv2D(32,3, padding='same')(input)\n",
        "    conv1_1 = tf.keras.layers.BatchNormalization()(conv1_1)\n",
        "    conv1_1 = tf.nn.relu(conv1_1)\n",
        "    conv1_2 = tf.keras.layers.Conv2D(32,3, padding='same')(conv1_1)\n",
        "    conv1_2 = tf.keras.layers.BatchNormalization()(conv1_2)\n",
        "    conv1_2 = tf.nn.relu(conv1_2)\n",
        "    pool_1 = tf.nn.max_pool(conv1_2, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
        "    conv2_1 = tf.keras.layers.Conv2D(64,3, padding='same')(pool_1)\n",
        "    conv2_1 = tf.keras.layers.BatchNormalization()(conv2_1)\n",
        "    conv2_1 = tf.nn.relu(conv2_1)\n",
        "    conv2_2 = tf.keras.layers.Conv2D(64,3, padding='same')(conv2_1)\n",
        "    conv2_2 = tf.keras.layers.BatchNormalization()(conv2_2)\n",
        "    conv2_2 = tf.nn.relu(conv2_2)\n",
        "    pool_2 = tf.nn.max_pool(conv2_2, [1,2,2,1], [1,2,2,1], padding='SAME')\n",
        "    conv3_1 = tf.keras.layers.Conv2D(128,3, padding='same')(pool_2)\n",
        "    conv3_1 = tf.keras.layers.BatchNormalization()(conv3_1)\n",
        "    conv3_1 = tf.nn.relu(conv3_1)\n",
        "    conv3_2 = tf.keras.layers.Conv2D(128,3, padding='same')(conv3_1)\n",
        "    conv3_2 = tf.keras.layers.BatchNormalization()(conv3_2)\n",
        "    conv3_2 = tf.nn.relu(conv3_2)\n",
        "    conv3_3 = tf.keras.layers.Conv2D(128,3, padding='same')(conv3_2)\n",
        "    feature_points = tf.contrib.layers.spatial_softmax(conv3_3)\n",
        "    fc1 = tf.keras.layers.Dense(64)(feature_points)\n",
        "    fc1 = tf.keras.layers.BatchNormalization()(fc1)\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "    fc2 = tf.keras.layers.Dense(64)(fc1)\n",
        "    fc2 = tf.keras.layers.BatchNormalization()(fc2)\n",
        "    fc2 = tf.nn.relu(fc2)\n",
        "    fc3 = tf.keras.layers.Dense(3)(fc2)\n",
        "    return fc3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPqmXtp0NjkS"
      },
      "source": [
        "def make_optimizer(pred, label):\n",
        "    loss = tf.reduce_mean(tf.reduce_sum((pred-label)**2, axis=-1))\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=3e-4).minimize(loss)\n",
        "    return loss, optimizer\n",
        "\n",
        "input = tf.placeholder(shape=[None, 480, 640, 3], dtype=tf.float32)\n",
        "label = tf.placeholder(shape=[None, 3], dtype = tf.float32)\n",
        "predict = make_model(input)\n",
        "loss, optimizer = make_optimizer(predict, label)\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "\n",
        "sess=tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "for i in tqdm(range(num_epochs), desc='Training'):\n",
        "    train_index = np.random.permutation(label_train.shape[0])\n",
        "    current = 0\n",
        "\n",
        "    losses = []\n",
        "    while current < label_train.shape[0]:\n",
        "        batch_image_train = image_train[train_index[current:min(current+batch_size, label_train.shape[0])]]\n",
        "        batch_label_train = label_train[train_index[current:min(current+batch_size, label_train.shape[0])]]\n",
        "        loss_val, _ = sess.run([loss, optimizer], feed_dict={input:batch_image_train, label:batch_label_train})\n",
        "        losses.append(loss_val)\n",
        "        current = min(current+batch_size, label_train.shape[0])\n",
        "    train_losses.append(np.mean(losses))\n",
        "\n",
        "    test_index = np.random.permutation(label_test.shape[0])\n",
        "    current = 0\n",
        "    losses = []\n",
        "    while current < label_test.shape[0]:\n",
        "        batch_image_test = image_test[test_index[current:min(current+batch_size, label_test.shape[0])]]\n",
        "        batch_label_test = label_test[test_index[current:min(current+batch_size, label_test.shape[0])]]\n",
        "        loss_val = sess.run(loss, feed_dict={input:batch_image_test, label:batch_label_test})\n",
        "        losses.append(loss_val)\n",
        "        current = min(current+batch_size, label_test.shape[0])\n",
        "    test_losses.append(np.mean(losses))\n",
        "\n",
        "    saver.save(sess, 'trained_model')\n",
        "    if i > 1:\n",
        "      clear_output()\n",
        "      fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "      ax1.plot(train_losses)\n",
        "      ax2.plot(test_losses)\n",
        "      ax1.set_xlabel('Epoch')\n",
        "      ax1.set_ylabel('Train Loss')\n",
        "      ax2.set_xlabel('Epoch')\n",
        "      ax2.set_ylabel('Test Loss')\n",
        "      plt.show()\n",
        "print(\"Final training loss: \", train_losses[-1])\n",
        "print(\"Final testing loss: \", test_losses[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EukgNo2DaG-6"
      },
      "source": [
        "%xdel image_train\n",
        "%xdel image_test\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVPQ4E7oHfDf"
      },
      "source": [
        "# Using the Model\n",
        "\n",
        "Now, let's use the model to make predictions for our Kalman Filter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-o6KI0XHuoZ"
      },
      "source": [
        "def load_dataset():\n",
        "    labels = np.load('./data/Q3B_data/Q3B_positions_gt.npy')\n",
        "    num_images = labels.shape[0]\n",
        "    images = np.empty(shape=(num_images, 480, 640,3))\n",
        "    for i in tqdm(range(num_images),desc=\"Loading data\"):\n",
        "        im = Image.open('./data/Q3B_data/img_%03d.png'%(i))\n",
        "        images[i] = np.array(im)/255.0\n",
        "    return images, labels\n",
        "\n",
        "image_infer, label_infer = load_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy7zUhtJRy2N"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "sess=tf.Session()\n",
        "input = tf.placeholder(shape=[1, 480, 640, 3], dtype=tf.float32)\n",
        "predict = make_model(input)\n",
        "saver = tf.train.Saver()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "saver.restore(sess, 'trained_model')\n",
        "\n",
        "predictions_val = []\n",
        "for img in image_infer:\n",
        "    pred_val = sess.run(predict, feed_dict={input:img[None]})\n",
        "    predictions_val.append(pred_val[0])\n",
        "predictions_val = np.array(predictions_val)\n",
        "print('Mean error: '+str(np.mean(np.linalg.norm(label_infer-predictions_val, axis=1))))\n",
        "np.save('Q3B_predictions.npy', predictions_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0OrMUQiaO36"
      },
      "source": [
        "%xdel image_infer\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4rFSMVvOBK_"
      },
      "source": [
        "def load_dataset():\n",
        "    labels = np.load('./data/Q3D_data/Q3D_positions_gt.npy')\n",
        "    num_images = labels.shape[0]\n",
        "    images = np.empty(shape=(num_images, 480, 640,3))\n",
        "    for i in tqdm(range(num_images),desc=\"Loading data\"):\n",
        "        im = Image.open('./data/Q3D_data/img_%03d.png'%(i))\n",
        "        images[i] = np.array(im)/255.0\n",
        "    return images, labels\n",
        "\n",
        "image_infer, label_infer = load_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fK4Pz6lR06s"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "sess=tf.Session()\n",
        "input = tf.placeholder(shape=[1, 480, 640, 3], dtype=tf.float32)\n",
        "predict = make_model(input)\n",
        "saver = tf.train.Saver()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "saver.restore(sess, 'trained_model')\n",
        "\n",
        "predictions_val = []\n",
        "for img in image_infer:\n",
        "    pred_val = sess.run(predict, feed_dict={input:img[None]})\n",
        "    predictions_val.append(pred_val[0])\n",
        "predictions_val = np.array(predictions_val)\n",
        "print('Mean error: '+str(np.mean(np.linalg.norm(label_infer-predictions_val, axis=1))))\n",
        "np.save('Q3D_predictions.npy', predictions_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b2iaKy1OJLu"
      },
      "source": [
        "# Finishing Problem 3\n",
        "Now that you have the predictions .npy files, you can use these along with the completed code in p3.py to generate the plots needed for the PDF report. Congratulations on nearing the end of the last 231a PSET!"
      ]
    }
  ]
}